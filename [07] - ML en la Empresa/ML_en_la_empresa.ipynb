{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoJa171199/INESDI_Data-Science_ML_IA/blob/main/%5B07%5D%20-%20ML%20en%20la%20Empresa/ML_en_la_empresa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🎯 Caso Práctico: Industrializar un modelo\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 📋 Información del Módulo\n",
        "\n",
        "**Asignatura:** Data Analytics: Data Science, Machine Learning e Inteligencia Artificial  \n",
        "**Máster:** FP en Business Analytics e Inteligencia Artificial  \n",
        "**Profesores:** Álvaro López Barberá\n",
        "**Ejemplo Práctico:**  ML en la empresa\n",
        "\n",
        "---\n",
        "\n",
        "## 🎓 Objetivo\n",
        "\n",
        "Desarrollar un modelo de lenguaje natural sobre Machine Learning, que nos conteste a nuestras preguntas."
      ],
      "metadata": {
        "id": "6TW047jpphEO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 📦 PASO 1: Instalar dependencias y Configuración Inicial"
      ],
      "metadata": {
        "id": "-YLy5GZmp47H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk scikit-learn fastapi uvicorn pydantic joblib requests numpy nest-asyncio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LgZoJy3qlxR",
        "outputId": "649bfda7-2211-4168-9949-89a38242909f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.118.2)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (0.37.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.11.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.48.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.49.0,>=0.40.0->fastapi) (4.11.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('all')  # Descarga todo (tarda ~5 min)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdNzkCoSgawz",
        "outputId": "9692e6e6-af0b-419f-fe9d-11d6870c9b2c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_rus.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package english_wordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/english_wordnet.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/maxent_treebank_pos_tagger_tab.zip.\n",
            "[nltk_data]    | Downloading package mock_corpus to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mock_corpus.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package tagsets_json to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets_json.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import joblib\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "3EyuHuSHgnS8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar recursos de NLTK\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "print(\"✅ Recursos descargados\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2bxHxeFrhHC",
        "outputId": "447e6131-17fc-40bf-99c6-3e6a03ab2fbf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Recursos descargados\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 📊 PASO 2: Crear Base de Conocimiento\n",
        "\n",
        "**Salida esperada:**\n",
        "```\n",
        "CONSTRUYENDO BASE DE CONOCIMIENTO\n",
        "✓ Total de preguntas en la base: 45\n",
        "✓ Vectorizando preguntas con TF-IDF...\n",
        "✓ Vectorización completada\n",
        "💾 Guardando chatbot en chatbot_data.pkl...\n",
        "✅ Chatbot guardado exitosamente"
      ],
      "metadata": {
        "id": "NOmv4rAaqBf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 📊 PASO 2: Crear Base de Conocimiento\n",
        "\n",
        "### Archivo: `01_crear_base_conocimiento.py`\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "PASO 1: CREAR BASE DE CONOCIMIENTO DEL CHATBOT\n",
        "Creamos una base de preguntas-respuestas sobre Machine Learning\n",
        "y la preparamos para calcular similitudes\n",
        "\"\"\"\n",
        "\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURACIÓN INICIAL: Descargar todos los recursos de NLTK\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"CONFIGURACIÓN INICIAL\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nDescargando recursos de NLTK (puede tardar unos segundos)...\")\n",
        "recursos_nltk = ['punkt', 'punkt_tab', 'stopwords', 'wordnet', 'omw-1.4']\n",
        "\n",
        "for recurso in recursos_nltk:\n",
        "    try:\n",
        "        nltk.download(recurso, quiet=True)\n",
        "        print(f\"  ✓ {recurso} descargado\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ⚠ Error descargando {recurso}: {e}\")\n",
        "\n",
        "print(\"\\n✅ Recursos de NLTK listos\\n\")\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "class ChatbotMLFAQ:\n",
        "    \"\"\"\n",
        "    Chatbot simple basado en similitud de texto para FAQs de Machine Learning\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Base de conocimiento: preguntas y respuestas sobre ML\n",
        "        self.qa_pairs = [\n",
        "            {\n",
        "                \"preguntas\": [\n",
        "                    \"¿Qué es machine learning?\",\n",
        "                    \"¿Qué es el aprendizaje automático?\",\n",
        "                    \"Define machine learning\",\n",
        "                    \"Explica qué es ML\"\n",
        "                ],\n",
        "                \"respuesta\": \"Machine Learning es una rama de la Inteligencia Artificial que permite a las máquinas aprender de los datos sin ser programadas explícitamente. Los algoritmos identifican patrones y toman decisiones basándose en ejemplos anteriores.\"\n",
        "            },\n",
        "            {\n",
        "                \"preguntas\": [\n",
        "                    \"¿Qué es overfitting?\",\n",
        "                    \"¿Qué es el sobreajuste?\",\n",
        "                    \"Explica overfitting\",\n",
        "                    \"Qué significa sobreajustar\"\n",
        "                ],\n",
        "                \"respuesta\": \"Overfitting ocurre cuando un modelo aprende demasiado bien los datos de entrenamiento, incluyendo el ruido. Esto hace que funcione muy bien con los datos de entrenamiento pero mal con datos nuevos. Se soluciona con validación cruzada, regularización o más datos.\"\n",
        "            },\n",
        "            {\n",
        "                \"preguntas\": [\n",
        "                    \"¿Qué es una red neuronal?\",\n",
        "                    \"Define red neuronal\",\n",
        "                    \"Explica las redes neuronales\",\n",
        "                    \"Qué son las neural networks\"\n",
        "                ],\n",
        "                \"respuesta\": \"Una red neuronal es un modelo de aprendizaje profundo inspirado en el cerebro humano. Está compuesta por capas de neuronas artificiales conectadas que procesan información. Se usa para tareas complejas como reconocimiento de imágenes o procesamiento de lenguaje natural.\"\n",
        "            },\n",
        "            {\n",
        "                \"preguntas\": [\n",
        "                    \"¿Qué diferencia hay entre clasificación y regresión?\",\n",
        "                    \"Clasificación vs regresión\",\n",
        "                    \"Diferencia entre clasificación y regresión\",\n",
        "                    \"Cuándo usar clasificación o regresión\"\n",
        "                ],\n",
        "                \"respuesta\": \"La clasificación predice categorías o clases (ej: spam/no spam, gato/perro), mientras que la regresión predice valores numéricos continuos (ej: precio de una casa, temperatura). Clasificación da etiquetas, regresión da números.\"\n",
        "            },\n",
        "            {\n",
        "                \"preguntas\": [\n",
        "                    \"¿Qué es el accuracy?\",\n",
        "                    \"Define accuracy\",\n",
        "                    \"Qué mide el accuracy\",\n",
        "                    \"Explica la métrica accuracy\"\n",
        "                ],\n",
        "                \"respuesta\": \"Accuracy (precisión) es el porcentaje de predicciones correctas sobre el total de predicciones. Se calcula como: (predicciones correctas / total de predicciones) × 100. Es útil cuando las clases están balanceadas, pero puede engañar con datos desbalanceados.\"\n",
        "            },\n",
        "            {\n",
        "                \"preguntas\": [\n",
        "                    \"¿Qué es gradient descent?\",\n",
        "                    \"Explica gradient descent\",\n",
        "                    \"Qué es el descenso de gradiente\",\n",
        "                    \"Cómo funciona gradient descent\"\n",
        "                ],\n",
        "                \"respuesta\": \"Gradient Descent es un algoritmo de optimización que ajusta los parámetros de un modelo para minimizar el error. Funciona calculando el gradiente (derivada) de la función de pérdida y moviéndose en la dirección opuesta para encontrar el mínimo.\"\n",
        "            },\n",
        "            {\n",
        "                \"preguntas\": [\n",
        "                    \"¿Qué es cross-validation?\",\n",
        "                    \"Explica la validación cruzada\",\n",
        "                    \"Para qué sirve cross-validation\",\n",
        "                    \"Qué es k-fold\"\n",
        "                ],\n",
        "                \"respuesta\": \"Cross-validation es una técnica para evaluar modelos dividing los datos en k partes (folds). Se entrena k veces usando k-1 partes para entrenar y 1 para validar, rotando. Esto da una estimación más robusta del rendimiento real del modelo.\"\n",
        "            },\n",
        "            {\n",
        "                \"preguntas\": [\n",
        "                    \"¿Qué es un Random Forest?\",\n",
        "                    \"Explica Random Forest\",\n",
        "                    \"Cómo funciona Random Forest\",\n",
        "                    \"Qué es bosque aleatorio\"\n",
        "                ],\n",
        "                \"respuesta\": \"Random Forest es un modelo ensemble que combina múltiples árboles de decisión. Cada árbol se entrena con una muestra aleatoria de datos y features. La predicción final es el promedio (regresión) o voto mayoritario (clasificación) de todos los árboles.\"\n",
        "            },\n",
        "            {\n",
        "                \"preguntas\": [\n",
        "                    \"¿Qué es feature engineering?\",\n",
        "                    \"Explica feature engineering\",\n",
        "                    \"Para qué sirve feature engineering\",\n",
        "                    \"Qué es ingeniería de características\"\n",
        "                ],\n",
        "                \"respuesta\": \"Feature Engineering es el proceso de crear nuevas características (features) a partir de los datos existentes para mejorar el rendimiento del modelo. Incluye transformaciones, combinaciones, extracciones y selección de las variables más relevantes.\"\n",
        "            },\n",
        "            {\n",
        "                \"preguntas\": [\n",
        "                    \"¿Qué es supervised learning?\",\n",
        "                    \"Explica aprendizaje supervisado\",\n",
        "                    \"Qué es supervised learning\",\n",
        "                    \"Diferencia entre supervisado y no supervisado\"\n",
        "                ],\n",
        "                \"respuesta\": \"Supervised Learning es cuando entrenamos un modelo con datos etiquetados (sabemos la respuesta correcta). El modelo aprende la relación entre inputs y outputs. Ejemplos: clasificación de emails, predicción de precios. Se diferencia del no supervisado que trabaja sin etiquetas.\"\n",
        "            },\n",
        "            {\n",
        "                \"preguntas\": [\n",
        "                    \"¿Qué es un hiperparámetro?\",\n",
        "                    \"Diferencia entre parámetro e hiperparámetro\",\n",
        "                    \"Explica hiperparámetros\",\n",
        "                    \"Qué son los hyperparameters\"\n",
        "                ],\n",
        "                \"respuesta\": \"Los hiperparámetros son configuraciones del modelo que definimos ANTES del entrenamiento (ej: learning rate, número de capas). Los parámetros son los valores que el modelo APRENDE durante el entrenamiento (ej: pesos de una red neuronal).\"\n",
        "            },\n",
        "            {\n",
        "                \"preguntas\": [\n",
        "                    \"Hola\",\n",
        "                    \"Buenos días\",\n",
        "                    \"Buenas tardes\",\n",
        "                    \"Hey\"\n",
        "                ],\n",
        "                \"respuesta\": \"¡Hola! Soy un chatbot especializado en Machine Learning. Puedo responder preguntas sobre conceptos de ML, algoritmos, métricas y más. ¿En qué puedo ayudarte?\"\n",
        "            },\n",
        "            {\n",
        "                \"preguntas\": [\n",
        "                    \"Gracias\",\n",
        "                    \"Muchas gracias\",\n",
        "                    \"Perfecto gracias\",\n",
        "                    \"Ok gracias\"\n",
        "                ],\n",
        "                \"respuesta\": \"¡De nada! Si tienes más preguntas sobre Machine Learning, estaré encantado de ayudarte. 😊\"\n",
        "            },\n",
        "            {\n",
        "                \"preguntas\": [\n",
        "                    \"Adiós\",\n",
        "                    \"Hasta luego\",\n",
        "                    \"Chao\",\n",
        "                    \"Nos vemos\"\n",
        "                ],\n",
        "                \"respuesta\": \"¡Hasta pronto! Que tengas un buen día aprendiendo Machine Learning. 🚀\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        # Preparar lematizador y stopwords\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "        self.stop_words = set(stopwords.words('spanish'))\n",
        "\n",
        "        # Vectorizador TF-IDF\n",
        "        self.vectorizer = None\n",
        "        self.question_vectors = None\n",
        "        self.all_questions = []\n",
        "        self.question_to_answer = {}\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        \"\"\"\n",
        "        Preprocesa el texto: tokeniza, elimina stopwords y lematiza\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Convertir a minúsculas\n",
        "            text = text.lower()\n",
        "\n",
        "            # Tokenizar\n",
        "            tokens = word_tokenize(text, language='spanish')\n",
        "\n",
        "            # Eliminar stopwords y lematizar\n",
        "            processed_tokens = [\n",
        "                self.lemmatizer.lemmatize(token)\n",
        "                for token in tokens\n",
        "                if token.isalnum() and token not in self.stop_words\n",
        "            ]\n",
        "\n",
        "            return ' '.join(processed_tokens)\n",
        "\n",
        "        except Exception as e:\n",
        "            # Si falla la tokenización en español, intentar con inglés\n",
        "            print(f\"⚠ Advertencia en preprocesamiento: {e}\")\n",
        "            try:\n",
        "                tokens = word_tokenize(text)\n",
        "                processed_tokens = [\n",
        "                    self.lemmatizer.lemmatize(token)\n",
        "                    for token in tokens\n",
        "                    if token.isalnum()\n",
        "                ]\n",
        "                return ' '.join(processed_tokens)\n",
        "            except:\n",
        "                # Último recurso: dividir por espacios\n",
        "                return ' '.join(text.lower().split())\n",
        "\n",
        "    def build_knowledge_base(self):\n",
        "        \"\"\"\n",
        "        Construye la base de conocimiento y vectoriza las preguntas\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"CONSTRUYENDO BASE DE CONOCIMIENTO\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Crear lista de todas las preguntas y mapeo a respuestas\n",
        "        for qa_pair in self.qa_pairs:\n",
        "            respuesta = qa_pair[\"respuesta\"]\n",
        "            for pregunta in qa_pair[\"preguntas\"]:\n",
        "                pregunta_procesada = self.preprocess_text(pregunta)\n",
        "                self.all_questions.append(pregunta_procesada)\n",
        "                self.question_to_answer[pregunta_procesada] = respuesta\n",
        "\n",
        "        print(f\"\\n✓ Total de preguntas en la base: {len(self.all_questions)}\")\n",
        "        print(f\"✓ Total de respuestas únicas: {len(self.qa_pairs)}\")\n",
        "\n",
        "        # Vectorizar preguntas usando TF-IDF\n",
        "        print(\"\\n Vectorizando preguntas con TF-IDF...\")\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "        self.question_vectors = self.vectorizer.fit_transform(self.all_questions)\n",
        "\n",
        "        print(\"✓ Vectorización completada\")\n",
        "\n",
        "    def get_response(self, user_question, threshold=0.3):\n",
        "        \"\"\"\n",
        "        Obtiene la respuesta más similar a la pregunta del usuario\n",
        "\n",
        "        Args:\n",
        "            user_question: Pregunta del usuario\n",
        "            threshold: Umbral mínimo de similitud (0-1)\n",
        "\n",
        "        Returns:\n",
        "            Respuesta del chatbot y score de confianza\n",
        "        \"\"\"\n",
        "        # Preprocesar pregunta del usuario\n",
        "        processed_question = self.preprocess_text(user_question)\n",
        "\n",
        "        # Vectorizar pregunta del usuario\n",
        "        user_vector = self.vectorizer.transform([processed_question])\n",
        "\n",
        "        # Calcular similitud con todas las preguntas\n",
        "        similarities = cosine_similarity(user_vector, self.question_vectors)[0]\n",
        "\n",
        "        # Encontrar la pregunta más similar\n",
        "        best_match_idx = np.argmax(similarities)\n",
        "        best_similarity = similarities[best_match_idx]\n",
        "\n",
        "        # Si la similitud es muy baja, no sabemos la respuesta\n",
        "        if best_similarity < threshold:\n",
        "            return {\n",
        "                \"answer\": \"Lo siento, no tengo información sobre eso. Intenta preguntarme sobre conceptos de Machine Learning como overfitting, redes neuronales, gradient descent, etc.\",\n",
        "                \"confidence\": float(best_similarity),\n",
        "                \"matched_question\": None\n",
        "            }\n",
        "\n",
        "        # Obtener la respuesta\n",
        "        matched_question = self.all_questions[best_match_idx]\n",
        "        answer = self.question_to_answer[matched_question]\n",
        "\n",
        "        return {\n",
        "            \"answer\": answer,\n",
        "            \"confidence\": float(best_similarity),\n",
        "            \"matched_question\": matched_question\n",
        "        }\n",
        "\n",
        "    def save(self, filename=\"chatbot_data.pkl\"):\n",
        "        \"\"\"\n",
        "        Guarda el chatbot completo\n",
        "        \"\"\"\n",
        "        print(f\"\\n💾 Guardando chatbot en {filename}...\")\n",
        "        joblib.dump({\n",
        "            'vectorizer': self.vectorizer,\n",
        "            'question_vectors': self.question_vectors,\n",
        "            'all_questions': self.all_questions,\n",
        "            'question_to_answer': self.question_to_answer,\n",
        "            'lemmatizer': self.lemmatizer,\n",
        "            'stop_words': self.stop_words\n",
        "        }, filename)\n",
        "        print(f\"✅ Chatbot guardado exitosamente\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Función principal para crear y guardar el chatbot\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"█\" * 60)\n",
        "    print(\" CREACIÓN DE CHATBOT ML - BASE DE CONOCIMIENTO\")\n",
        "    print(\"█\" * 60)\n",
        "\n",
        "    # Crear chatbot\n",
        "    chatbot = ChatbotMLFAQ()\n",
        "\n",
        "    # Construir base de conocimiento\n",
        "    chatbot.build_knowledge_base()\n",
        "\n",
        "    # Guardar chatbot\n",
        "    chatbot.save()\n",
        "\n",
        "    # Prueba rápida\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"PRUEBA RÁPIDA DEL CHATBOT\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    test_questions = [\n",
        "        \"¿Qué es machine learning?\",\n",
        "        \"Explícame overfitting\",\n",
        "        \"¿Cómo funciona gradient descent?\"\n",
        "    ]\n",
        "\n",
        "    for question in test_questions:\n",
        "        print(f\"\\n❓ Pregunta: {question}\")\n",
        "        response = chatbot.get_response(question)\n",
        "        print(f\"🤖 Respuesta: {response['answer'][:100]}...\")\n",
        "        print(f\"📊 Confianza: {response['confidence']:.2%}\")\n",
        "\n",
        "    print(\"\\n\" + \"█\" * 60)\n",
        "    print(\" ✅ CHATBOT CREADO Y GUARDADO EXITOSAMENTE\")\n",
        "    print(\"█\" * 60)\n",
        "    print(\"\\nAhora ejecuta: python 02_api_chatbot.py\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d0f3012-c6bc-40b2-cd74-efa5a086debd",
        "id": "54rbr9IWlyRc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CONFIGURACIÓN INICIAL\n",
            "============================================================\n",
            "\n",
            "Descargando recursos de NLTK (puede tardar unos segundos)...\n",
            "  ✓ punkt descargado\n",
            "  ✓ punkt_tab descargado\n",
            "  ✓ stopwords descargado\n",
            "  ✓ wordnet descargado\n",
            "  ✓ omw-1.4 descargado\n",
            "\n",
            "✅ Recursos de NLTK listos\n",
            "\n",
            "\n",
            "████████████████████████████████████████████████████████████\n",
            " CREACIÓN DE CHATBOT ML - BASE DE CONOCIMIENTO\n",
            "████████████████████████████████████████████████████████████\n",
            "\n",
            "============================================================\n",
            "CONSTRUYENDO BASE DE CONOCIMIENTO\n",
            "============================================================\n",
            "\n",
            "✓ Total de preguntas en la base: 56\n",
            "✓ Total de respuestas únicas: 14\n",
            "\n",
            " Vectorizando preguntas con TF-IDF...\n",
            "✓ Vectorización completada\n",
            "\n",
            "💾 Guardando chatbot en chatbot_data.pkl...\n",
            "✅ Chatbot guardado exitosamente\n",
            "\n",
            "============================================================\n",
            "PRUEBA RÁPIDA DEL CHATBOT\n",
            "============================================================\n",
            "\n",
            "❓ Pregunta: ¿Qué es machine learning?\n",
            "🤖 Respuesta: Machine Learning es una rama de la Inteligencia Artificial que permite a las máquinas aprender de lo...\n",
            "📊 Confianza: 100.00%\n",
            "\n",
            "❓ Pregunta: Explícame overfitting\n",
            "🤖 Respuesta: Overfitting ocurre cuando un modelo aprende demasiado bien los datos de entrenamiento, incluyendo el...\n",
            "📊 Confianza: 100.00%\n",
            "\n",
            "❓ Pregunta: ¿Cómo funciona gradient descent?\n",
            "🤖 Respuesta: Gradient Descent es un algoritmo de optimización que ajusta los parámetros de un modelo para minimiz...\n",
            "📊 Confianza: 85.50%\n",
            "\n",
            "████████████████████████████████████████████████████████████\n",
            " ✅ CHATBOT CREADO Y GUARDADO EXITOSAMENTE\n",
            "████████████████████████████████████████████████████████████\n",
            "\n",
            "Ahora ejecuta: python 02_api_chatbot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 🌐 PASO 3: API REST del Chatbot\n",
        "\n",
        "**Salida esperada:**\n",
        "```\n",
        "INICIANDO API DEL CHATBOT ML\n",
        "📂 Cargando chatbot desde chatbot_data.pkl...\n",
        "✅ Chatbot cargado exitosamente\n",
        "   - Preguntas en base: 45\n",
        "\n",
        "Iniciando servidor en: http://127.0.0.1:8000\n",
        "Documentación: http://127.0.0.1:8000/docs"
      ],
      "metadata": {
        "id": "snkxoUCErsJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 🌐 PASO 3: API REST del Chatbot\n",
        "\n",
        "### Archivo: `02_api_chatbot.py`\n",
        "\n",
        "\"\"\"\n",
        "PASO 2: API REST PARA EL CHATBOT\n",
        "Expone el chatbot a través de una API REST con FastAPI\n",
        "\"\"\"\n",
        "\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel, Field\n",
        "import joblib\n",
        "from typing import Optional\n",
        "import uvicorn\n",
        "import os\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURACIÓN DE LA API\n",
        "# ============================================================================\n",
        "\n",
        "app = FastAPI(\n",
        "    title=\"ML FAQ Chatbot API\",\n",
        "    description=\"API de chatbot para preguntas sobre Machine Learning\",\n",
        "    version=\"1.0.0\"\n",
        ")\n",
        "\n",
        "# Configurar CORS\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# Variable global para el chatbot\n",
        "chatbot_data = None\n",
        "\n",
        "# ============================================================================\n",
        "# MODELOS DE DATOS\n",
        "# ============================================================================\n",
        "\n",
        "class ChatRequest(BaseModel):\n",
        "    \"\"\"\n",
        "    Modelo de entrada: pregunta del usuario\n",
        "    \"\"\"\n",
        "    question: str = Field(\n",
        "        ...,\n",
        "        description=\"Pregunta del usuario sobre Machine Learning\",\n",
        "        min_length=1,\n",
        "        max_length=500\n",
        "    )\n",
        "    threshold: Optional[float] = Field(\n",
        "        0.3,\n",
        "        description=\"Umbral mínimo de confianza (0-1)\",\n",
        "        ge=0.0,\n",
        "        le=1.0\n",
        "    )\n",
        "\n",
        "    class Config:\n",
        "        json_schema_extra = {\n",
        "            \"example\": {\n",
        "                \"question\": \"¿Qué es overfitting?\",\n",
        "                \"threshold\": 0.3\n",
        "            }\n",
        "        }\n",
        "\n",
        "class ChatResponse(BaseModel):\n",
        "    \"\"\"\n",
        "    Modelo de respuesta del chatbot\n",
        "    \"\"\"\n",
        "    question: str\n",
        "    answer: str\n",
        "    confidence: float\n",
        "    matched_question: Optional[str]\n",
        "    status: str\n",
        "\n",
        "# ============================================================================\n",
        "# CLASE CHATBOT (versión para API)\n",
        "# ============================================================================\n",
        "\n",
        "class ChatbotAPI:\n",
        "    \"\"\"\n",
        "    Versión del chatbot para usar en la API\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_file=\"chatbot_data.pkl\"):\n",
        "        \"\"\"\n",
        "        Carga el chatbot desde el archivo guardado\n",
        "        \"\"\"\n",
        "        if not os.path.exists(data_file):\n",
        "            raise FileNotFoundError(\n",
        "                f\"No se encontró {data_file}. \"\n",
        "                f\"Ejecuta primero: python 01_crear_base_conocimiento.py\"\n",
        "            )\n",
        "\n",
        "        print(f\"📂 Cargando chatbot desde {data_file}...\")\n",
        "        data = joblib.load(data_file)\n",
        "\n",
        "        self.vectorizer = data['vectorizer']\n",
        "        self.question_vectors = data['question_vectors']\n",
        "        self.all_questions = data['all_questions']\n",
        "        self.question_to_answer = data['question_to_answer']\n",
        "        self.lemmatizer = data['lemmatizer']\n",
        "        self.stop_words = data['stop_words']\n",
        "\n",
        "        print(\"✅ Chatbot cargado exitosamente\")\n",
        "        print(f\"   - Preguntas en base: {len(self.all_questions)}\")\n",
        "        print(f\"   - Respuestas únicas: {len(set(self.question_to_answer.values()))}\")\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        \"\"\"\n",
        "        Preprocesa el texto\n",
        "        \"\"\"\n",
        "        from nltk.tokenize import word_tokenize\n",
        "\n",
        "        text = text.lower()\n",
        "        tokens = word_tokenize(text, language='spanish')\n",
        "        processed_tokens = [\n",
        "            self.lemmatizer.lemmatize(token)\n",
        "            for token in tokens\n",
        "            if token.isalnum() and token not in self.stop_words\n",
        "        ]\n",
        "        return ' '.join(processed_tokens)\n",
        "\n",
        "    def get_response(self, user_question, threshold=0.3):\n",
        "        \"\"\"\n",
        "        Obtiene respuesta para la pregunta del usuario\n",
        "        \"\"\"\n",
        "        from sklearn.metrics.pairwise import cosine_similarity\n",
        "        import numpy as np\n",
        "\n",
        "        # Preprocesar pregunta\n",
        "        processed_question = self.preprocess_text(user_question)\n",
        "\n",
        "        # Vectorizar\n",
        "        user_vector = self.vectorizer.transform([processed_question])\n",
        "\n",
        "        # Calcular similitud\n",
        "        similarities = cosine_similarity(user_vector, self.question_vectors)[0]\n",
        "\n",
        "        # Mejor coincidencia\n",
        "        best_match_idx = np.argmax(similarities)\n",
        "        best_similarity = similarities[best_match_idx]\n",
        "\n",
        "        # Verificar umbral\n",
        "        if best_similarity < threshold:\n",
        "            return {\n",
        "                \"answer\": \"Lo siento, no tengo información sobre eso. Intenta preguntarme sobre conceptos de Machine Learning como overfitting, redes neuronales, gradient descent, Random Forest, etc.\",\n",
        "                \"confidence\": float(best_similarity),\n",
        "                \"matched_question\": None,\n",
        "                \"status\": \"low_confidence\"\n",
        "            }\n",
        "\n",
        "        # Obtener respuesta\n",
        "        matched_question = self.all_questions[best_match_idx]\n",
        "        answer = self.question_to_answer[matched_question]\n",
        "\n",
        "        return {\n",
        "            \"answer\": answer,\n",
        "            \"confidence\": float(best_similarity),\n",
        "            \"matched_question\": matched_question,\n",
        "            \"status\": \"success\"\n",
        "        }\n",
        "\n",
        "# ============================================================================\n",
        "# EVENTOS DE LA API\n",
        "# ============================================================================\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "async def startup_event():\n",
        "    \"\"\"\n",
        "    Carga el chatbot al iniciar la API\n",
        "    \"\"\"\n",
        "    global chatbot_data\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"INICIANDO API DEL CHATBOT ML\")\n",
        "    print(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "    try:\n",
        "        chatbot_data = ChatbotAPI()\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"\\n❌ ERROR: {e}\\n\")\n",
        "        raise\n",
        "\n",
        "# ============================================================================\n",
        "# ENDPOINTS\n",
        "# ============================================================================\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    \"\"\"\n",
        "    Endpoint raíz - información de la API\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"message\": \"ML FAQ Chatbot API\",\n",
        "        \"version\": \"1.0.0\",\n",
        "        \"description\": \"Chatbot especializado en preguntas sobre Machine Learning\",\n",
        "        \"endpoints\": {\n",
        "            \"chat\": \"/chat (POST)\",\n",
        "            \"health\": \"/health (GET)\",\n",
        "            \"stats\": \"/stats (GET)\",\n",
        "            \"examples\": \"/examples (GET)\",\n",
        "            \"docs\": \"/docs (GET)\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "@app.get(\"/health\")\n",
        "async def health():\n",
        "    \"\"\"\n",
        "    Verificación de salud de la API\n",
        "    \"\"\"\n",
        "    if chatbot_data is None:\n",
        "        raise HTTPException(status_code=503, detail=\"Chatbot no cargado\")\n",
        "\n",
        "    return {\n",
        "        \"status\": \"healthy\",\n",
        "        \"chatbot_loaded\": True,\n",
        "        \"questions_in_base\": len(chatbot_data.all_questions)\n",
        "    }\n",
        "\n",
        "@app.get(\"/stats\")\n",
        "async def stats():\n",
        "    \"\"\"\n",
        "    Estadísticas del chatbot\n",
        "    \"\"\"\n",
        "    if chatbot_data is None:\n",
        "        raise HTTPException(status_code=503, detail=\"Chatbot no cargado\")\n",
        "\n",
        "    return {\n",
        "        \"total_questions\": len(chatbot_data.all_questions),\n",
        "        \"unique_answers\": len(set(chatbot_data.question_to_answer.values())),\n",
        "        \"topics\": [\n",
        "            \"Machine Learning básico\",\n",
        "            \"Overfitting y validación\",\n",
        "            \"Algoritmos (Random Forest, Gradient Descent)\",\n",
        "            \"Métricas (Accuracy)\",\n",
        "            \"Conceptos (Feature Engineering, Hiperparámetros)\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "@app.get(\"/examples\")\n",
        "async def examples():\n",
        "    \"\"\"\n",
        "    Ejemplos de preguntas que el chatbot puede responder\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"examples\": [\n",
        "            \"¿Qué es machine learning?\",\n",
        "            \"Explícame qué es overfitting\",\n",
        "            \"¿Qué diferencia hay entre clasificación y regresión?\",\n",
        "            \"¿Qué es gradient descent?\",\n",
        "            \"¿Para qué sirve cross-validation?\",\n",
        "            \"¿Qué es Random Forest?\",\n",
        "            \"Explica feature engineering\",\n",
        "            \"¿Qué es un hiperparámetro?\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "@app.post(\"/chat\", response_model=ChatResponse)\n",
        "async def chat(request: ChatRequest):\n",
        "    \"\"\"\n",
        "    Endpoint principal del chatbot\n",
        "\n",
        "    Recibe una pregunta y devuelve la respuesta del chatbot\n",
        "    \"\"\"\n",
        "    if chatbot_data is None:\n",
        "        raise HTTPException(status_code=503, detail=\"Chatbot no cargado\")\n",
        "\n",
        "    try:\n",
        "        # Obtener respuesta del chatbot\n",
        "        response = chatbot_data.get_response(\n",
        "            request.question,\n",
        "            threshold=request.threshold\n",
        "        )\n",
        "\n",
        "        return ChatResponse(\n",
        "            question=request.question,\n",
        "            answer=response[\"answer\"],\n",
        "            confidence=response[\"confidence\"],\n",
        "            matched_question=response[\"matched_question\"],\n",
        "            status=response[\"status\"]\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        raise HTTPException(\n",
        "            status_code=500,\n",
        "            detail=f\"Error al procesar la pregunta: {str(e)}\"\n",
        "        )\n",
        "\n",
        "# ============================================================================\n",
        "# EJECUTAR SERVIDOR\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"SERVIDOR API - ML FAQ Chatbot\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"\\nIniciando servidor en: http://127.0.0.1:8000\")\n",
        "    print(\"Documentación: http://127.0.0.1:8000/docs\")\n",
        "    print(\"\\nPresiona CTRL+C para detener\\n\")\n",
        "\n",
        "    # Configuración para evitar conflictos con event loops existentes\n",
        "    import sys\n",
        "\n",
        "    # Detectar si estamos en Jupyter/Colab\n",
        "    try:\n",
        "        get_ipython()\n",
        "        IN_NOTEBOOK = True\n",
        "    except NameError:\n",
        "        IN_NOTEBOOK = False\n",
        "\n",
        "    if IN_NOTEBOOK:\n",
        "        # En Jupyter/Colab, usar nest_asyncio\n",
        "        print(\"⚠️  Detectado entorno Jupyter/Colab\")\n",
        "        print(\"   Ejecutando servidor en modo compatible...\\n\")\n",
        "\n",
        "        try:\n",
        "            import nest_asyncio\n",
        "            nest_asyncio.apply()\n",
        "        except ImportError:\n",
        "            print(\"❌ Instalando nest_asyncio...\")\n",
        "            import subprocess\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"nest_asyncio\"])\n",
        "            import nest_asyncio\n",
        "            nest_asyncio.apply()\n",
        "\n",
        "        # Iniciar servidor en segundo plano\n",
        "        import threading\n",
        "\n",
        "        def run_server():\n",
        "            uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
        "\n",
        "        server_thread = threading.Thread(target=run_server, daemon=True)\n",
        "        server_thread.start()\n",
        "\n",
        "        print(\"✅ Servidor iniciado en segundo plano\")\n",
        "        print(\"   Accede a: http://127.0.0.1:8000/docs\")\n",
        "        print(\"   El servidor se detendrá cuando cierres el notebook\\n\")\n",
        "    else:\n",
        "        # En terminal normal\n",
        "        uvicorn.run(\n",
        "            app,\n",
        "            host=\"0.0.0.0\",\n",
        "            port=8000,\n",
        "            log_level=\"info\"\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab7f61b5-260b-4331-f215-14dbebd9dff5",
        "id": "d_Fzo9JkmEnn"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4206241009.py:171: DeprecationWarning: \n",
            "        on_event is deprecated, use lifespan event handlers instead.\n",
            "\n",
            "        Read more about it in the\n",
            "        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n",
            "        \n",
            "  @app.on_event(\"startup\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "SERVIDOR API - ML FAQ Chatbot\n",
            "============================================================\n",
            "\n",
            "Iniciando servidor en: http://127.0.0.1:8000\n",
            "Documentación: http://127.0.0.1:8000/docs\n",
            "\n",
            "Presiona CTRL+C para detener\n",
            "\n",
            "⚠️  Detectado entorno Jupyter/Colab\n",
            "   Ejecutando servidor en modo compatible...\n",
            "\n",
            "✅ Servidor iniciado en segundo plano\n",
            "   Accede a: http://127.0.0.1:8000/docs\n",
            "   El servidor se detendrá cuando cierres el notebook\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 🧪 PASO 4: Cliente de Prueba"
      ],
      "metadata": {
        "id": "xmGYeJN7r5O_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 🧪 PASO 4: Cliente de Prueba\n",
        "\n",
        "### Archivo: `03_test_chatbot.py`\n",
        "\"\"\"\n",
        "PASO 3: CLIENTE PARA PROBAR EL CHATBOT\n",
        "Script para probar la API del chatbot\n",
        "\"\"\"\n",
        "\n",
        "import requests\n",
        "import json\n",
        "\n",
        "BASE_URL = \"http://127.0.0.1:8000\"\n",
        "\n",
        "def print_response(title, response):\n",
        "    \"\"\"\n",
        "    Imprime la respuesta de manera bonita\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(f\"  {title}\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Status: {response.status_code}\")\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        print(json.dumps(data, indent=2, ensure_ascii=False))\n",
        "    else:\n",
        "        print(f\"Error: {response.text}\")\n",
        "\n",
        "def test_health():\n",
        "    \"\"\"\n",
        "    Test del health check\n",
        "    \"\"\"\n",
        "    response = requests.get(f\"{BASE_URL}/health\")\n",
        "    print_response(\"TEST 1: Health Check\", response)\n",
        "\n",
        "def test_stats():\n",
        "    \"\"\"\n",
        "    Test de estadísticas\n",
        "    \"\"\"\n",
        "    response = requests.get(f\"{BASE_URL}/stats\")\n",
        "    print_response(\"TEST 2: Estadísticas del Chatbot\", response)\n",
        "\n",
        "def test_examples():\n",
        "    \"\"\"\n",
        "    Test de ejemplos\n",
        "    \"\"\"\n",
        "    response = requests.get(f\"{BASE_URL}/examples\")\n",
        "    print_response(\"TEST 3: Preguntas de Ejemplo\", response)\n",
        "\n",
        "def test_chat_questions():\n",
        "    \"\"\"\n",
        "    Test de preguntas al chatbot\n",
        "    \"\"\"\n",
        "    questions = [\n",
        "        \"¿Qué es machine learning?\",\n",
        "        \"Explícame el overfitting por favor\",\n",
        "        \"¿Cuál es la diferencia entre clasificación y regresión?\",\n",
        "        \"¿Qué es el gradient descent?\",\n",
        "        \"Hola chatbot\",\n",
        "        \"Gracias por la ayuda\",\n",
        "        \"¿Qué es la física cuántica?\"  # Esta NO debería saber\n",
        "    ]\n",
        "\n",
        "    for i, question in enumerate(questions, 1):\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"  TEST 4.{i}: Pregunta al Chatbot\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"❓ Pregunta: {question}\")\n",
        "\n",
        "        response = requests.post(\n",
        "            f\"{BASE_URL}/chat\",\n",
        "            json={\"question\": question}\n",
        "        )\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            print(f\"\\n🤖 Respuesta:\")\n",
        "            print(f\"   {data['answer']}\")\n",
        "            print(f\"\\n📊 Confianza: {data['confidence']:.2%}\")\n",
        "            print(f\"📌 Estado: {data['status']}\")\n",
        "            if data['matched_question']:\n",
        "                print(f\"🔍 Pregunta similar: {data['matched_question']}\")\n",
        "        else:\n",
        "            print(f\"❌ Error: {response.text}\")\n",
        "\n",
        "def run_all_tests():\n",
        "    \"\"\"\n",
        "    Ejecuta todos los tests\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"█\" * 70)\n",
        "    print(\"  SUITE DE TESTS - ML FAQ CHATBOT API\")\n",
        "    print(\"█\" * 70)\n",
        "\n",
        "    try:\n",
        "        test_health()\n",
        "        test_stats()\n",
        "        test_examples()\n",
        "        test_chat_questions()\n",
        "\n",
        "        print(\"\\n\" + \"█\" * 70)\n",
        "        print(\"  ✅ TODOS LOS TESTS COMPLETADOS\")\n",
        "        print(\"█\" * 70 + \"\\n\")\n",
        "\n",
        "    except requests.exceptions.ConnectionError:\n",
        "        print(\"\\n❌ ERROR: No se puede conectar a la API\")\n",
        "        print(\"Asegúrate de que el servidor esté corriendo:\")\n",
        "        print(\"   python 02_api_chatbot.py\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ ERROR: {e}\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_all_tests()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11c74069-b288-4034-9410-39c7be695b01",
        "id": "iLwGXTrYmRei"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "██████████████████████████████████████████████████████████████████████\n",
            "  SUITE DE TESTS - ML FAQ CHATBOT API\n",
            "██████████████████████████████████████████████████████████████████████\n",
            "\n",
            "❌ ERROR: No se puede conectar a la API\n",
            "Asegúrate de que el servidor esté corriendo:\n",
            "   python 02_api_chatbot.py\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 🧪 PASO 5: Lanzar el servidor en local"
      ],
      "metadata": {
        "id": "B1VSOAVqr_IP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# EXPONER SERVIDOR EN GOOGLE COLAB\n",
        "# ========================================\n",
        "\n",
        "# Usar el proxy de Colab\n",
        "from google.colab.output import eval_js\n",
        "print(\"🔄 Obteniendo URL del servidor...\")\n",
        "\n",
        "# La URL base de Colab\n",
        "colab_url = eval_js(\"google.colab.kernel.proxyPort(8000)\")\n",
        "\n",
        "print(\"\\n\" + \"✅\" * 35)\n",
        "print(\"\\n   🎉 SERVIDOR ACTIVO EN COLAB 🎉\")\n",
        "print(\"\\n\" + \"✅\" * 35)\n",
        "print(f\"\\n🌐 URL del servidor:\")\n",
        "print(f\"   {colab_url}\")\n",
        "print(f\"\\n📖 ABRE ESTA URL EN TU NAVEGADOR:\")\n",
        "print(f\"   👉 {colab_url}/docs\")\n",
        "print(f\"\\n📍 Otros endpoints:\")\n",
        "print(f\"   • Health:   {colab_url}/health\")\n",
        "print(f\"   • Chat:     {colab_url}/chat\")\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"\\n💡 Click en la URL para abrir en nueva pestaña\")\n",
        "print(\"=\" * 70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "E6na00WNmDo8",
        "outputId": "46d73c23-bcd6-4acc-f55d-81c434eb57e0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [265]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Obteniendo URL del servidor...\n",
            "\n",
            "============================================================\n",
            "INICIANDO API DEL CHATBOT ML\n",
            "============================================================\n",
            "\n",
            "📂 Cargando chatbot desde chatbot_data.pkl...\n",
            "✅ Chatbot cargado exitosamente\n",
            "   - Preguntas en base: 56\n",
            "   - Respuestas únicas: 14\n",
            "\n",
            "✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅\n",
            "\n",
            "   🎉 SERVIDOR ACTIVO EN COLAB 🎉\n",
            "\n",
            "✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅✅\n",
            "\n",
            "🌐 URL del servidor:\n",
            "   https://8000-m-s-ng57csdi055l-a.us-central1-0.prod.colab.dev\n",
            "\n",
            "📖 ABRE ESTA URL EN TU NAVEGADOR:\n",
            "   👉 https://8000-m-s-ng57csdi055l-a.us-central1-0.prod.colab.dev/docs\n",
            "\n",
            "📍 Otros endpoints:\n",
            "   • Health:   https://8000-m-s-ng57csdi055l-a.us-central1-0.prod.colab.dev/health\n",
            "   • Chat:     https://8000-m-s-ng57csdi055l-a.us-central1-0.prod.colab.dev/chat\n",
            "\n",
            "======================================================================\n",
            "\n",
            "💡 Click en la URL para abrir en nueva pestaña\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 💡 CÓMO FUNCIONA EL CHATBOT\n",
        "\n",
        "### 1. Procesamiento de Texto (NLP)\n",
        "\n",
        "```python\n",
        "Pregunta original: \"¿Qué es el overfitting?\"\n",
        "                    ↓\n",
        "Preprocesamiento:  - Minúsculas\n",
        "                   - Tokenización\n",
        "                   - Eliminar stopwords (\"qué\", \"es\", \"el\")\n",
        "                   - Lematización\n",
        "                    ↓\n",
        "Texto procesado:   \"overfitting\"\n",
        "```\n",
        "\n",
        "### 2. Vectorización TF-IDF\n",
        "\n",
        "```\n",
        "TF-IDF convierte texto en números:\n",
        "\n",
        "\"overfitting\" → [0.0, 0.0, 0.87, 0.0, 0.0, ...]\n",
        "                 (vector de 100+ dimensiones)\n",
        "```\n",
        "\n",
        "### 3. Similitud Coseno\n",
        "\n",
        "```python\n",
        "Pregunta usuario:    [0.0, 0.0, 0.87, ...]\n",
        "                            ↓\n",
        "         Calcular similitud con TODAS las preguntas\n",
        "                            ↓\n",
        "Pregunta 1: 0.23 ←\n",
        "Pregunta 2: 0.95 ← ¡MEJOR MATCH!\n",
        "Pregunta 3: 0.15 ←\n",
        "                            ↓\n",
        "            Devolver respuesta de Pregunta 2\n",
        "```\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "_Y2LKYissh4G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 🎓 EJERCICIOS INTERESANTES\n",
        "\n",
        "### Ejercicio 1: Añadir más preguntas (Fácil)\n",
        "Modifica `01_crear_base_conocimiento.py` para añadir 3 nuevas preguntas sobre Deep Learning.\n",
        "\n",
        "### Ejercicio 2: Ajustar el threshold (Medio)\n",
        "Experimenta cambiando el threshold en `/chat`. ¿Qué pasa si lo subes a 0.7? ¿Y si lo bajas a 0.1?\n",
        "\n",
        "### Ejercicio 3: Endpoint de feedback (Medio)\n",
        "Crea un nuevo endpoint `/feedback` que permita al usuario indicar si la respuesta fue útil.\n",
        "\n",
        "### Ejercicio 4: Historial de conversación (Avanzado)\n",
        "Implementa un sistema que guarde el historial de preguntas en memoria para mantener contexto.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "5gd74GLUssXK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ CHECKLIST DE LA SESIÓN\n",
        "\n",
        "- [ ] Entender qué es industrialización de modelos\n",
        "- [ ] Conocer conceptos básicos de NLP (tokenización, TF-IDF)\n",
        "- [ ] Comprender cómo funciona similitud coseno\n",
        "- [ ] Crear una base de conocimiento\n",
        "- [ ] Serializar datos con pickle\n",
        "- [ ] Crear una API REST con FastAPI\n",
        "- [ ] Probar la API con diferentes métodos\n",
        "- [ ] Explorar documentación automática (Swagger)\n",
        "- [ ] Modificar y extender el chatbot\n",
        "\n",
        "---\n",
        "\n",
        "## 📚 RECURSOS ADICIONALES\n",
        "\n",
        "### Documentación:\n",
        "- **NLTK**: https://www.nltk.org/\n",
        "- **Scikit-learn TfidfVectorizer**: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
        "- **FastAPI**: https://fastapi.tiangolo.com/\n",
        "- **Cosine Similarity**: https://en.wikipedia.org/wiki/Cosine_similarity\n",
        "\n",
        "### Tutoriales:\n",
        "- Introduction to NLP with NLTK\n",
        "- Building REST APIs with FastAPI\n",
        "- Text Similarity with TF-IDF"
      ],
      "metadata": {
        "id": "BczROsC6tMVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🎓 PREGUNTAS FRECUENTES\n",
        "\n",
        "**P: ¿Por qué usar TF-IDF y no simplemente contar palabras?**\n",
        "R: TF-IDF da más peso a palabras importantes y menos a palabras comunes. \"Overfitting\" es más importante que \"qué\" o \"es\".\n",
        "\n",
        "**P: ¿Esto es un modelo de Machine Learning real?**\n",
        "R: No es un modelo que \"aprende\", pero usa técnicas de ML (vectorización, similitud). Es perfecto para entender industrialización.\n",
        "\n",
        "**P: ¿Puedo usarlo para otros idiomas?**\n",
        "R: Sí, solo cambia `language='spanish'` por `language='english'` en el código y ajusta los stopwords.\n",
        "\n",
        "**P: ¿Cómo lo escalo para miles de preguntas?**\n",
        "R: Considera usar Elasticsearch o FAISS para búsquedas vectoriales más eficientes.\n",
        "\n",
        "**P: ¿Funciona con WhatsApp/Telegram?**\n",
        "R: Sí, puedes integrar la API con cualquier plataforma usando sus APIs (ej: Twilio para WhatsApp).\n"
      ],
      "metadata": {
        "id": "-aNoNxGTtWCg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🎉 MENSAJE FINAL\n",
        "\n",
        "Este proyecto demuestra que industrializar un modelo no siempre requiere infraestructura compleja. Con FastAPI + pickle + un poco de NLP, puedes crear un servicio útil en menos de 200 líneas de código.\n",
        "\n",
        "**Lo más importante:** Los estudiantes ven el ciclo completo:\n",
        "1. Crear conocimiento → 2. Guardarlo → 3. Exponerlo como API → 4. Consumirlo\n",
        "\n",
        "¡Esto es industrialización en su forma más práctica!"
      ],
      "metadata": {
        "id": "rXYA0DXEtLi4"
      }
    }
  ]
}