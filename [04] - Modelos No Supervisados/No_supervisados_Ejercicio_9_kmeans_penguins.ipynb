{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtoralg/INESDI_Data-Science_ML_IA/blob/main/%5B04%5D%20-%20Modelos%20No%20Supervisados/No_supervisados_Ejercicio_9_kmeans_penguins.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "780c7767",
      "metadata": {
        "id": "780c7767"
      },
      "source": [
        "# No supervisados - Ejercicio 9: kmeans_penguins.ipynb\n",
        "\n",
        "Este notebook es **You do**. Vas a trabajar de forma autónoma sobre el dataset *Palmer Penguins* aplicando **KMeans (+ comparación con DBSCAN)**, **PCA** y **LOF**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c275b04",
      "metadata": {
        "id": "3c275b04"
      },
      "source": [
        "## Objetivos\n",
        "\n",
        "- Cargar y explorar el dataset `penguins`.\n",
        "- Preparar los datos (limpieza, encoding, escalado).\n",
        "- Aplicar PCA para visualización y compresión.\n",
        "- Entrenar KMeans, comparar con DBSCAN y detectar outliers con LOF.\n",
        "- Perfilar clusters y outliers y escribir conclusiones.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "681e167a",
      "metadata": {
        "id": "681e167a"
      },
      "source": [
        "## Nota rápida antes de empezar\n",
        "\n",
        "Trabaja en este orden: carga → EDA → limpieza/selección → preprocesado → PCA → clustering → outliers → perfilado. Guarda el notebook con tus respuestas y añade al final un párrafo con tus decisiones (qué parámetros elegiste y por qué)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "106385b2",
      "metadata": {
        "id": "106385b2"
      },
      "outputs": [],
      "source": [
        "# IMPORTS (ejecuta esta celda para disponer de las librerías)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style='whitegrid')\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import LocalOutlierFactor, NearestNeighbors\n",
        "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# No modifiques esta celda salvo para instalar paquetes si te falta alguno (por ejemplo, pip install seaborn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc4484ca",
      "metadata": {
        "id": "cc4484ca"
      },
      "outputs": [],
      "source": [
        "# CARGA DE DATOS\n",
        "# TODO: carga el dataset 'penguins'. Opciones:\n",
        "#  - usar seaborn: df = sns.load_dataset('penguins')\n",
        "#  - o cargar desde la URL raw: 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/penguins.csv'\n",
        "#  - comprueba que el DataFrame se ha cargado correctamente con df.head() y df.shape\n",
        "# Tu objetivo: dejar un DataFrame llamado `df` listo para EDA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e5a61fd",
      "metadata": {
        "id": "6e5a61fd"
      },
      "outputs": [],
      "source": [
        "# EXPLORACIÓN INICIAL\n",
        "# TODO:\n",
        "# 1) Muestra df.info(), df.describe().T y el porcentaje de nulos por columna.\n",
        "# 2) Observa la distribución de las columnas categóricas 'species' y 'sex' con df['species'].value_counts() y sns.countplot.\n",
        "# 3) Visualiza relaciones entre las variables numéricas con sns.pairplot(...) para hacerte una idea de agrupamientos naturales.\n",
        "# Resultado esperado: entender cuántas filas útiles hay y si necesitas imputar o eliminar filas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "489654bf",
      "metadata": {
        "id": "489654bf"
      },
      "outputs": [],
      "source": [
        "# SELECCIÓN Y LIMPIEZA\n",
        "# TODO:\n",
        "# - Define vars_numericas = df.select_dtypes(include=[np.number]).columns\n",
        "# - Define vars_categoricas = df.select_dtypes(include=['object','category']).columns\n",
        "# - Decide cómo tratar nulos: imputa (media/mediana) o elimina filas con df.dropna(subset=vars_numericas).\n",
        "# - Crea df_clean resultado de esa operación y comprueba su shape.\n",
        "# Debes terminar con un DataFrame `df_clean` sin nulos en las numéricas que vas a usar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de1a9521",
      "metadata": {
        "id": "de1a9521"
      },
      "outputs": [],
      "source": [
        "# ENCODING + ESCALADO\n",
        "# TODO:\n",
        "# - Si vas a usar variables categóricas, aplica OneHotEncoder(drop='first') y concatena con las numéricas.\n",
        "# - Crea una matriz X_full (numpy array) con todas las features que usarás para clustering.\n",
        "# - Aplica StandardScaler() y guarda el resultado en `X_scaled` (numpy array o DataFrame) conservando el orden de filas.\n",
        "# Al final debes tener X_scaled y también las listas vars_numericas y vars_categoricas usadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54fc6871",
      "metadata": {
        "id": "54fc6871"
      },
      "outputs": [],
      "source": [
        "# PCA\n",
        "# TODO:\n",
        "# - Ajusta PCA(n_components=2) sobre X_scaled para visualización y guarda X_pca2.\n",
        "# - Muestra pca.explained_variance_ratio_ y dibuja un barplot con las dos primeras componentes.\n",
        "# - (Opcional) Ajusta PCA(n_components=0.90) para conocer cuántas componentes necesitas para retener 90% de varianza.\n",
        "# Resultado: X_pca2 y, opcionalmente, X_pca90."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f5f98dd",
      "metadata": {
        "id": "4f5f98dd"
      },
      "outputs": [],
      "source": [
        "# KMEANS (explora manualmente k)\n",
        "# TODO:\n",
        "# - Prueba k en range(2,9). Para cada k: entrena KMeans(n_clusters=k, random_state=42, n_init=10), calcula inertia y silhouette_score.\n",
        "# - Construye un pequeño DataFrame con k, inertia y silhouette y dibuja ambos gráficos (inertia vs k, silhouette vs k).\n",
        "# - Elige un k razonable y entrena KMeans con ese k. Guarda etiquetas en labels_km y añade a df_clean['cluster_km'].\n",
        "# - Visualiza en PCA 2D (X_pca2) coloreando por cluster_km.\n",
        "# Nota: silhouette_score requiere al menos 2 clusters distintos y no funciona si todos pertenecen a la misma etiqueta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a4ef674",
      "metadata": {
        "id": "1a4ef674"
      },
      "outputs": [],
      "source": [
        "# DBSCAN (comparativa)\n",
        "# TODO:\n",
        "# - Dibuja el k-distance plot (NearestNeighbors) para elegir un rango de eps: neigh = NearestNeighbors(n_neighbors=5); distances = ...; plt.plot(sorted(distances[:, -1])).\n",
        "# - Prueba al menos dos configuraciones de DBSCAN(eps=..., min_samples=...) y guarda labels_db.\n",
        "# - Añade df_clean['cluster_db'] = labels_db y muestra np.unique(labels_db) y pd.Series(labels_db).value_counts().\n",
        "# - Calcula adjusted_rand_score(labels_km, labels_db) para cuantificar similitud entre particiones (si procede).\n",
        "# - Visualiza labels_db en PCA 2D."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86e8b596",
      "metadata": {
        "id": "86e8b596"
      },
      "outputs": [],
      "source": [
        "# LOF (detección de outliers)\n",
        "# TODO:\n",
        "# - Ajusta LocalOutlierFactor con distintos n_neighbors y contamination (ej. 0.05).\n",
        "# - Usa lof.fit_predict(X_scaled) para obtener etiquetas (1 normal, -1 outlier) y guarda en df_clean['lof_label'].\n",
        "# - Cuenta cuántos outliers detectas y visualízalos en PCA 2D (color por lof_label).\n",
        "# - Compara los outliers LOF con el ruido (-1) detectado por DBSCAN: ¿coinciden muchos casos?\n",
        "# Resultado: lista de índices detectados como outliers y visualización clara."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91745ffc",
      "metadata": {
        "id": "91745ffc"
      },
      "outputs": [],
      "source": [
        "# PERFILADO DE CLUSTERS Y OUTLIERS\n",
        "# TODO:\n",
        "# - Calcula medias por cluster_km: df_clean.groupby('cluster_km')[vars_numericas].mean()\n",
        "# - Muestra algunos ejemplos de outliers: df_clean[df_clean['lof_label']==-1].head()\n",
        "# - Propón 2 acciones prácticas (texto) basadas en los clusters y en los outliers (p. ej. investigar outliers o crear campañas dirigidas a un cluster concreto)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e903de5",
      "metadata": {
        "id": "8e903de5"
      },
      "source": [
        "### Entrega\n",
        "\n",
        "En la última celda escribe un párrafo (4-6 líneas) que incluya: k elegido y por qué, parámetros DBSCAN y LOF que ajustaste, principales hallazgos (qué clusters existen y qué tipo de outliers detectaste) y 2 recomendaciones prácticas. Guarda y descarga el notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26f20c0b",
      "metadata": {
        "id": "26f20c0b"
      },
      "outputs": [],
      "source": [
        "# Aquí escribe tu entrega"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}