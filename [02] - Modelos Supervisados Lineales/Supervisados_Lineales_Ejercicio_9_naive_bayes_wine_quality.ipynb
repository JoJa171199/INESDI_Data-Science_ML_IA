{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtoralg/INESDI_Data-Science_ML_IA/blob/main/%5B02%5D%20-%20Modelos%20Supervisados%20Lineales/Supervisados_Lineales_Ejercicio_9_naive_bayes_wine_quality.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8048859",
      "metadata": {
        "id": "d8048859"
      },
      "source": [
        "## Supervisados Lineales - Ejercicio 9: naive_bayes_wine_quality.ipynb\n",
        "\n",
        "En este ejercicio **tú** construirás y evaluarás **tres variantes de Naive Bayes** sobre el dataset **Wine Quality (red)**:\n",
        "- **GaussianNB** (rasgos continuos ~ normales)\n",
        "- **CategoricalNB** (discretización por bins)\n",
        "- **MultinomialNB** (rasgos no negativos tipo conteo)\n",
        "\n",
        "Al final harás una **comparativa** con matrices de confusión y una tabla de métricas."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a687f68",
      "metadata": {
        "id": "5a687f68"
      },
      "source": [
        "### Objetivos\n",
        "- **O1.** Cargar y preparar el dataset (binarización opcional de `quality`).\n",
        "- **O2.** Entrenar y evaluar GaussianNB, CategoricalNB y MultinomialNB.\n",
        "- **O3.** Comparar resultados (accuracy, F1/ROC-AUC) y analizar **matrices de confusión**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4e98d39",
      "metadata": {
        "id": "d4e98d39"
      },
      "source": [
        "### Dataset\n",
        "**Wine Quality (red)** de UCI. 1599 filas, 11 variables fisicoquímicas y `quality` en [0–10] (típicamente 3–8).\n",
        "\n",
        "Fuente directa: https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\n",
        "\n",
        "**Formulación del target (elige una):**\n",
        "- **Binaria**: `quality >= 7` → 1 (alta), en otro caso 0.\n",
        "- **Multiclase**: usar `quality` tal cual."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3847416b",
      "metadata": {
        "id": "3847416b"
      },
      "source": [
        "### 1) Librerías, utilidades y carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c87a32aa",
      "metadata": {
        "id": "c87a32aa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB, CategoricalNB, MultinomialNB\n",
        "from sklearn.preprocessing import KBinsDiscretizer, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "sns.set(style='whitegrid')\n",
        "\n",
        "def plot_confusion(cm, title, ax=None, labels=('Pred 0','Pred 1'), ticks=('Real 0','Real 1')):\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(figsize=(4,3))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "                xticklabels=labels, yticklabels=ticks, ax=ax)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel('Predicción')\n",
        "    ax.set_ylabel('Real')\n",
        "    return ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f934cb2a",
      "metadata": {
        "id": "f934cb2a"
      },
      "outputs": [],
      "source": [
        "# TODO: Carga el dataset desde la URL (usar sep=';')\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
        "# df = pd.read_csv(url, sep=';')\n",
        "# TODO: inspección básica -> df.shape, df.head(), df['quality'].value_counts().sort_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec5abbb5",
      "metadata": {
        "id": "ec5abbb5"
      },
      "source": [
        "### 2) Formulación del problema (binaria o multiclase)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95f7df01",
      "metadata": {
        "id": "95f7df01"
      },
      "outputs": [],
      "source": [
        "# Opción A (binaria):\n",
        "# TODO: y = (df['quality'] >= 7).astype(int)\n",
        "# TODO: X = df.drop(columns=['quality'])\n",
        "\n",
        "# Opción B (multiclase):\n",
        "# TODO: y = df['quality']\n",
        "# TODO: X = df.drop(columns=['quality'])\n",
        "\n",
        "# SUGERENCIA: empieza con la versión binaria para comparar matrices de confusión más fácilmente\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a978f3d3",
      "metadata": {
        "id": "a978f3d3"
      },
      "source": [
        "### 3) Train/Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90f9e46a",
      "metadata": {
        "id": "90f9e46a"
      },
      "outputs": [],
      "source": [
        "# TODO: Divide en train/test (80/20), usa stratify=y si es binario/multiclase desbalanceado, random_state=42\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dbafcc2",
      "metadata": {
        "id": "8dbafcc2"
      },
      "source": [
        "### 4) Gaussian Naive Bayes (baseline con rasgos continuos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2e8c6e7",
      "metadata": {
        "id": "a2e8c6e7"
      },
      "outputs": [],
      "source": [
        "# TODO: Entrena y evalúa GaussianNB, predice y calcula accuracy, f1, auc, cm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de6470f9",
      "metadata": {
        "id": "de6470f9"
      },
      "source": [
        "### 5) Categorical Naive Bayes (discretización por bins)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "881f12d8",
      "metadata": {
        "id": "881f12d8"
      },
      "outputs": [],
      "source": [
        "# TODO: Discretiza rasgos numéricos con KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')\n",
        "# TODO: Entrena CatgoricalNB, predice y calcula accuracy, f1, auc, cm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dfcd633",
      "metadata": {
        "id": "6dfcd633"
      },
      "source": [
        "### 6) Multinomial Naive Bayes (rasgos no negativos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0730be44",
      "metadata": {
        "id": "0730be44"
      },
      "outputs": [],
      "source": [
        "# TODO: Reescala rasgos con MinMaxScaler() a [0,1] y entrena MultinomialNB\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59e3ee4f",
      "metadata": {
        "id": "59e3ee4f"
      },
      "source": [
        "### 7) Comparativa final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe3f7b1c",
      "metadata": {
        "id": "fe3f7b1c"
      },
      "outputs": [],
      "source": [
        "# TODO: Muestra matrices de confusión de los tres modelos lado a lado\n",
        "# SUGERENCIA (binario):\n",
        "# fig, axes = plt.subplots(1,3, figsize=(14,4))\n",
        "# plot_confusion(cm_gnb, f'GaussianNB\\nAcc={acc_gnb:.2f}', ax=axes[0])\n",
        "# plot_confusion(cm_cnb, f'CategoricalNB\\nAcc={acc_cnb:.2f}', ax=axes[1])\n",
        "# plot_confusion(cm_mnb, f'MultinomialNB\\nAcc={acc_mnb:.2f}', ax=axes[2])\n",
        "# plt.tight_layout(); plt.show()g\n",
        "\n",
        "# TODO: Construye un DataFrame resumen con accuracy, F1 (macro si multiclase) y AUC (si binario)\n",
        "# metrics = pd.DataFrame({ })\n",
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "601f80e1",
      "metadata": {
        "id": "601f80e1"
      },
      "source": [
        "### Conclusión\n",
        "- **GaussianNB**: baseline para rasgos continuos; rápido y simple.\n",
        "- **CategoricalNB**: tras discretizar; puede ganar robustez si los rangos capturan bien el patrón.\n",
        "- **MultinomialNB**: pensado para **conteos**; en datos continuos reescalados no siempre encaja, pero compensa probar.\n",
        "\n",
        "Comenta diferencias en **falsos positivos/negativos** y cuál modelo elegirías según la métrica prioritaria."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}