{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtoralg/INESDI_Data-Science_ML_IA/blob/main/%5B03%5D%20-%20Modelos%20Supervisados%20Alternativos/Supervisados_Alternativos_Ejercicio_4_svm_iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2509eda5",
      "metadata": {
        "id": "2509eda5"
      },
      "source": [
        "# Supervisados Alternativos - Ejercicio 4: svm_iris.ipynb\n",
        "\n",
        "Este notebook es un **I do** completamente resuelto."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c5984d4",
      "metadata": {
        "id": "7c5984d4"
      },
      "source": [
        "## Objetivos\n",
        "\n",
        "- Cargar y explorar el dataset Iris.\n",
        "- Entrenar SVM lineal y SVM con kernel RBF.\n",
        "- Visualizar fronteras de decisión y vectores de soporte (2D y PCA).\n",
        "- Comparar métricas (accuracy, matriz de confusión, classification report) y discutir trade-offs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3aa761c",
      "metadata": {
        "id": "e3aa761c"
      },
      "source": [
        "## Descripción del dataset\n",
        "\n",
        "Iris: 150 muestras, 3 clases (setosa, versicolor, virginica), 4 features (sepal length/width, petal length/width). Dataset ideal para visualizar clasificadores y márgenes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6d5f0b6",
      "metadata": {
        "id": "a6d5f0b6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style='whitegrid')\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.decomposition import PCA\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42ce4ca0",
      "metadata": {
        "id": "42ce4ca0"
      },
      "outputs": [],
      "source": [
        "# 1) Cargar dataset Iris\n",
        "iris = load_iris()\n",
        "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y = pd.Series(iris.target, name='species')\n",
        "target_names = iris.target_names\n",
        "\n",
        "print('Dimensiones:', X.shape)\n",
        "display(X.head())\n",
        "print('\\nDistribución por clase:')\n",
        "display(y.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d135164",
      "metadata": {
        "id": "6d135164"
      },
      "source": [
        "## 2) Preprocesado: escalado\n",
        "\n",
        "SVM es sensible a la escala de las features. Aplicamos `StandardScaler` a todas las columnas numéricas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59f065a0",
      "metadata": {
        "id": "59f065a0"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "display(X_scaled.describe().T)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bc8640a",
      "metadata": {
        "id": "6bc8640a"
      },
      "source": [
        "## 3) División train/test (estratificada)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa2f5d8b",
      "metadata": {
        "id": "fa2f5d8b"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "print('Train:', X_train.shape, 'Test:', X_test.shape)\n",
        "display(y_train.value_counts(normalize=True).round(3))\n",
        "display(y_test.value_counts(normalize=True).round(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffac8f40",
      "metadata": {
        "id": "ffac8f40"
      },
      "source": [
        "## 4) Entrenamiento: SVM lineal (kernel='linear')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ab7ab25",
      "metadata": {
        "id": "0ab7ab25"
      },
      "outputs": [],
      "source": [
        "# Creamos y entrenamos un SVM lineal\n",
        "svm_lin = SVC(kernel='linear', C=1.0, probability=True)\n",
        "svm_lin.fit(X_train, y_train)\n",
        "y_pred_lin = svm_lin.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy SVM lineal:', accuracy_score(y_test, y_pred_lin))\n",
        "print('\\nClassification report (SVM lineal):\\n')\n",
        "print(classification_report(y_test, y_pred_lin, target_names=target_names))"
      ],
      "metadata": {
        "id": "UJketKz6CjS4"
      },
      "id": "UJketKz6CjS4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_lin = confusion_matrix(y_test, y_pred_lin)\n",
        "sns.heatmap(cm_lin, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
        "plt.title('Confusion matrix - SVM linear')\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Real')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LQFZ883lClHc"
      },
      "id": "LQFZ883lClHc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c529c925",
      "metadata": {
        "id": "c529c925"
      },
      "source": [
        "## 5) Entrenamiento: SVM con kernel RBF (kernel='rbf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3172f989",
      "metadata": {
        "id": "3172f989"
      },
      "outputs": [],
      "source": [
        "# SVM RBF con parámetros por defecto (gamma='scale') y C=1.0\n",
        "svm_rbf = SVC(kernel='rbf', C=1.0, gamma='scale', probability=True)\n",
        "svm_rbf.fit(X_train, y_train)\n",
        "y_pred_rbf = svm_rbf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy SVM RBF:', accuracy_score(y_test, y_pred_rbf))\n",
        "print('\\nClassification report (SVM RBF):\\n')\n",
        "print(classification_report(y_test, y_pred_rbf, target_names=target_names))\n"
      ],
      "metadata": {
        "id": "LTis44QXCpk_"
      },
      "id": "LTis44QXCpk_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_rbf = confusion_matrix(y_test, y_pred_rbf)\n",
        "sns.heatmap(cm_rbf, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
        "plt.title('Confusion matrix - SVM RBF')\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Real')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YOd_14elCrWT"
      },
      "id": "YOd_14elCrWT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0b0519ed",
      "metadata": {
        "id": "0b0519ed"
      },
      "source": [
        "## 6) Comparativa simple de métricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5237ece7",
      "metadata": {
        "id": "5237ece7"
      },
      "outputs": [],
      "source": [
        "metrics = pd.DataFrame({\n",
        "    'model': ['svm_linear','svm_rbf'],\n",
        "    'accuracy': [accuracy_score(y_test, y_pred_lin), accuracy_score(y_test, y_pred_rbf)]\n",
        "})\n",
        "metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5415f33",
      "metadata": {
        "id": "d5415f33"
      },
      "source": [
        "## 7) Visualización de márgenes y vectores de soporte en 2D (dos features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "444dcc0e",
      "metadata": {
        "id": "444dcc0e"
      },
      "outputs": [],
      "source": [
        "# Para visualizar márgenes usamos las dos primeras features (sepal length, sepal width)\n",
        "feature_idx = [0, 1]\n",
        "X2 = X_scaled.iloc[:, feature_idx]\n",
        "X2_train, X2_test = X2.loc[X_train.index], X2.loc[X_test.index]\n",
        "\n",
        "svm_lin_2d = SVC(kernel='linear', C=1.0)\n",
        "svm_lin_2d.fit(X2_train, y_train)\n",
        "\n",
        "xx, yy = np.meshgrid(np.linspace(X2.iloc[:,0].min()-0.5, X2.iloc[:,0].max()+0.5, 300),\n",
        "                     np.linspace(X2.iloc[:,1].min()-0.5, X2.iloc[:,1].max()+0.5, 300))\n",
        "Z = svm_lin_2d.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.contourf(xx, yy, Z, alpha=0.3, cmap='Accent')\n",
        "sns.scatterplot(x=X2_test.iloc[:,0], y=X2_test.iloc[:,1], hue=y_test.map({0:target_names[0],1:target_names[1],2:target_names[2]}),\n",
        "                palette='deep', edgecolor='k')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b381313",
      "metadata": {
        "id": "4b381313"
      },
      "source": [
        "## 8) Visualización en espacio PCA (todas las features -> 2D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fdfa4c7",
      "metadata": {
        "id": "6fdfa4c7"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "X_pca_df = pd.DataFrame(X_pca, columns=['PC1','PC2'])\n",
        "X_pca_train, X_pca_test = X_pca_df.loc[X_train.index], X_pca_df.loc[X_test.index]\n",
        "\n",
        "svm_rbf_pca = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
        "svm_rbf_pca.fit(X_pca_train, y_train)\n",
        "\n",
        "xx, yy = np.meshgrid(np.linspace(X_pca_df['PC1'].min()-1, X_pca_df['PC1'].max()+1, 300),\n",
        "                     np.linspace(X_pca_df['PC2'].min()-1, X_pca_df['PC2'].max()+1, 300))\n",
        "Z = svm_rbf_pca.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.contourf(xx, yy, Z, alpha=0.3, cmap='Accent')\n",
        "sns.scatterplot(x=X_pca_test['PC1'], y=X_pca_test['PC2'], hue=y_test.map({0:target_names[0],1:target_names[1],2:target_names[2]}),\n",
        "                palette='deep', edgecolor='k')\n",
        "plt.xlabel('PC1')\n",
        "plt.ylabel('PC2')\n",
        "plt.title('SVM RBF - decision boundary en PCA 2D (todas las features)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83c66add",
      "metadata": {
        "id": "83c66add"
      },
      "source": [
        "## 9) Sensibilidad a hiperparámetros\n",
        "\n",
        "Probamos manualmente C en {0.1, 1, 10} y, para RBF, gamma en {0.01, 0.1, 1}. Comparamos accuracy en test para ver el efecto de regularización y del kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b270f61c",
      "metadata": {
        "id": "b270f61c"
      },
      "outputs": [],
      "source": [
        "Cs = [0.1, 1, 10]\n",
        "gammas = [0.01, 0.1, 1]\n",
        "records = []\n",
        "for C in Cs:\n",
        "    svm = SVC(kernel='linear', C=C)\n",
        "    svm.fit(X_train, y_train)\n",
        "    acc = accuracy_score(y_test, svm.predict(X_test))\n",
        "    records.append({'model':'linear','C':C,'gamma':None,'accuracy':acc})\n",
        "for C in Cs:\n",
        "    for g in gammas:\n",
        "        svm = SVC(kernel='rbf', C=C, gamma=g)\n",
        "        svm.fit(X_train, y_train)\n",
        "        acc = accuracy_score(y_test, svm.predict(X_test))\n",
        "        records.append({'model':'rbf','C':C,'gamma':g,'accuracy':acc})\n",
        "pd.DataFrame(records).sort_values(['model','accuracy'], ascending=[True,False]).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c2afd92",
      "metadata": {
        "id": "9c2afd92"
      },
      "source": [
        "## 10) Conclusión\n",
        "- SVM lineal es rápido y funciona bien cuando las clases son linealmente separables en el espacio transformado; RBF añade flexibilidad con el coste de coste computacional y riesgo de overfitting si gamma es alto.\n",
        "- Aumentar C reduce el margen (menos regularización) y puede aumentar precisión de entrenamiento a costa de generalización.\n",
        "- Visualizar vectores de soporte y fronteras ayuda a entender por qué SVM puede ser robusto en datasets con pocos ejemplos."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}