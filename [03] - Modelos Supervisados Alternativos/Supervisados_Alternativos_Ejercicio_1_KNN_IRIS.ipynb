{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtoralg/INESDI_Data-Science_ML_IA/blob/main/%5B03%5D%20-%20Modelos%20Supervisados%20Alternativos/Supervisados_Alternativos_Ejercicio_1_KNN_IRIS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc9eb426",
      "metadata": {
        "id": "fc9eb426"
      },
      "source": [
        "# Supervisados Alternativos - Ejercicio 1: knn_iris.ipynb\n",
        "\n",
        "Este notebook es un **I do**: todo resuelto y explicado paso a paso."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72867a89",
      "metadata": {
        "id": "72867a89"
      },
      "source": [
        "## Objetivos\n",
        "\n",
        "- Cargar y explorar el dataset Iris.\n",
        "- Entender y aplicar KNN: efecto de `k`, `weights` y escalado.\n",
        "- Probar manualmente varios `k` y visualizar resultados.\n",
        "- Mostrar fronteras de decisión en 2D y evaluación del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "624da4a8",
      "metadata": {
        "id": "624da4a8"
      },
      "source": [
        "## Descripción del dataset\n",
        "\n",
        "El dataset Iris contiene 150 muestras de flores de tres especies (setosa, versicolor, virginica) con 4 características: sepal length, sepal width, petal length y petal width. Es ideal para explicar conceptos de clasificación y visualizar fronteras de decisión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66512719",
      "metadata": {
        "id": "66512719"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style='whitegrid')\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea4d2dec",
      "metadata": {
        "id": "ea4d2dec"
      },
      "outputs": [],
      "source": [
        "# 1) Cargar dataset Iris\n",
        "iris = load_iris()\n",
        "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y = pd.Series(iris.target, name='species')\n",
        "target_names = iris.target_names\n",
        "\n",
        "print('Dimensiones:', X.shape)\n",
        "display(X.head())\n",
        "print('\\nClases:', np.unique(y))\n",
        "print('\\nDistribución por clase:')\n",
        "display(y.value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c15bd00e",
      "metadata": {
        "id": "c15bd00e"
      },
      "source": [
        "## 2) Exploración rápida y visualización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d964d495",
      "metadata": {
        "id": "d964d495"
      },
      "outputs": [],
      "source": [
        "# Pairplot para ver relaciones entre variables (colorear por especie)\n",
        "sns.pairplot(pd.concat([X, y], axis=1), hue='species', corner=True)\n",
        "plt.suptitle('Pairplot Iris (variables originales)', y=1.02)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4256362c",
      "metadata": {
        "id": "4256362c"
      },
      "source": [
        "## 3) Preprocesado: escalado\n",
        "\n",
        "KNN es sensible a la escala porque usa distancias. Aplicaremos StandardScaler a todas las características."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "252d4454",
      "metadata": {
        "id": "252d4454"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "display(X_scaled.describe().T)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f1b0288",
      "metadata": {
        "id": "7f1b0288"
      },
      "source": [
        "## 4) División train/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38893b31",
      "metadata": {
        "id": "38893b31"
      },
      "outputs": [],
      "source": [
        "# Split estratificado para mantener proporciones de clase\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "print('Train:', X_train.shape, 'Test:', X_test.shape)\n",
        "print('Distribución train:', y_train.value_counts().to_dict())\n",
        "print('Distribución test:', y_test.value_counts().to_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14bff520",
      "metadata": {
        "id": "14bff520"
      },
      "source": [
        "## 5) Baseline: KNN con k=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2edf4ba1",
      "metadata": {
        "id": "2edf4ba1"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
        "print('\\nClassification report:\\n')\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
        "plt.title('Confusion matrix - KNN k=5')\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Real')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da8fd963",
      "metadata": {
        "id": "da8fd963"
      },
      "source": [
        "## 6) Probar manualmente varios valores de `k`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "230aab96",
      "metadata": {
        "id": "230aab96"
      },
      "outputs": [],
      "source": [
        "# Probamos varios k manualmente y registramos accuracy en test\n",
        "k_list = [1,3,5,7,9,11,15]\n",
        "results = []\n",
        "for k in k_list:\n",
        "    model = KNeighborsClassifier(n_neighbors=k)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred_k = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred_k)\n",
        "    results.append({'k': k, 'accuracy': acc})\n",
        "results_df = pd.DataFrame(results).set_index('k')\n",
        "results_df\n",
        "\n",
        "# Elegimos el k con mejor accuracy sobre test (manual, para clase)\n",
        "best_k = int(results_df['accuracy'].idxmax())\n",
        "best_acc = results_df['accuracy'].max()\n",
        "print(f'Best k (test): {best_k} -> accuracy = {best_acc:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca59c607",
      "metadata": {
        "id": "ca59c607"
      },
      "source": [
        "## 7) Visualizar accuracy en función de k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "623bea85",
      "metadata": {
        "id": "623bea85"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(results_df.index, results_df['accuracy'], marker='o')\n",
        "plt.xlabel('k (n_neighbors)')\n",
        "plt.ylabel('Test Accuracy')\n",
        "plt.title('Efecto de k en KNN (evaluado en test set)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e79c3c76",
      "metadata": {
        "id": "e79c3c76"
      },
      "source": [
        "## 8) Fronteras de decisión en 2D (dos features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fe8d8f2",
      "metadata": {
        "id": "5fe8d8f2"
      },
      "outputs": [],
      "source": [
        "# Para visualizar fronteras tomamos las dos primeras features: sepal length (0) y sepal width (1)\n",
        "feature_idx = [0, 1]\n",
        "X2 = X_scaled.iloc[:, feature_idx]\n",
        "X2_train, X2_test = X2.loc[X_train.index], X2.loc[X_test.index]\n",
        "\n",
        "model_2d = KNeighborsClassifier(n_neighbors=best_k)\n",
        "model_2d.fit(X2_train, y_train)\n",
        "\n",
        "# Meshgrid\n",
        "x_min, x_max = X2.iloc[:,0].min() - 0.5, X2.iloc[:,0].max() + 0.5\n",
        "y_min, y_max = X2.iloc[:,1].min() - 0.5, X2.iloc[:,1].max() + 0.5\n",
        "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300), np.linspace(y_min, y_max, 300))\n",
        "Z = model_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.contourf(xx, yy, Z, alpha=0.3, cmap='Accent')\n",
        "sns.scatterplot(x=X2_test.iloc[:,0], y=X2_test.iloc[:,1], hue=y_test.map({0:target_names[0],1:target_names[1],2:target_names[2]}),\n",
        "                palette='deep', edgecolor='k')\n",
        "plt.xlabel(X2.columns[0])\n",
        "plt.ylabel(X2.columns[1])\n",
        "plt.title('Decision boundary (2 features) - KNN')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e079503f",
      "metadata": {
        "id": "e079503f"
      },
      "source": [
        "## 10) Conclusión\n",
        "- KNN es un algoritmo sencillo e intuitivo: la elección de `k` y el escalado son críticos.\n",
        "- `weights='distance'` puede ayudar cuando hay clases cercanas con densidades distintas.\n",
        "- Visualizar las fronteras en 2D (features reales o PCA) ayuda a entender el comportamiento del clasificador.\n",
        "\n",
        "En próximos ejercicios compararemos KNN con SVM sobre los mismos datasets para contrastar inductivas y comportamientos."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}